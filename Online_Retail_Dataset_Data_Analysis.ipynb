{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nataliia-data-analyst/Nataliia-data-analyst/blob/main/Online_Retail_Dataset_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install pandas matplotlib statsmodels\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn statsmodels\n",
        "!pip install matplotlib\n",
        "!pip install matplotlib.pyplot\n",
        "!pip install seaborn\n",
        "!pip install datetime\n",
        "!pip install warnings\n",
        "!pip install csv\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.cluster import KMeans\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "NLMN1n7UlnkB",
        "collapsed": true
      },
      "id": "NLMN1n7UlnkB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qeq8nm2zEa2b"
      },
      "id": "qeq8nm2zEa2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we will be working with the \"Online Retail\" dataset. This dataset contains online store transactions and provides detailed information about purchases, including the invoice number, product code, quantity of items sold, date, product price, customer ID, and the buyer's country.\n",
        "\n",
        "The dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/352/online+retail), titled \"Online Retail\", contains transactional data of a UK-based online retail company. Below is the description of the columns in this dataset:\n",
        "\n",
        "InvoiceNo: A unique number assigned to each invoice. It indicates the specific transaction. If the invoice starts with a 'C', it denotes a cancellation.\n",
        "\n",
        "StockCode: A unique code assigned to each product (item) in the transaction.\n",
        "\n",
        "Description: A description of the product (item) associated with the StockCode.\n",
        "\n",
        "Quantity: The number of products (items) per transaction (can be negative for product returns).\n",
        "\n",
        "InvoiceDate: The date and time when the transaction occurred.\n",
        "\n",
        "UnitPrice: The price of a single product (item) at the time of the transaction.\n",
        "\n",
        "CustomerID: A unique identifier for each customer.\n",
        "\n",
        "Country: The country where the customer is located.\n",
        "\n",
        "This dataset contains transactions between 01/12/2010 and 09/12/2011, primarily involving wholesale customers across different countries."
      ],
      "metadata": {
        "id": "E-8ZBoF4QcOD"
      },
      "id": "E-8ZBoF4QcOD"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/PythonMarathon/Colab Notebooks/Online Retail.csv')"
      ],
      "metadata": {
        "id": "ODQSwpvNUuyS"
      },
      "id": "ODQSwpvNUuyS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "LiWjp_D5no-e"
      },
      "id": "LiWjp_D5no-e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the first 5 records:"
      ],
      "metadata": {
        "id": "DNRojbWHnrDx"
      },
      "id": "DNRojbWHnrDx"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() # df.head(5)"
      ],
      "metadata": {
        "id": "cb-J3RSdnqLS"
      },
      "id": "cb-J3RSdnqLS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can review specific rows in the data as follows:"
      ],
      "metadata": {
        "id": "1yN87rKxOwyk"
      },
      "id": "1yN87rKxOwyk"
    },
    {
      "cell_type": "code",
      "source": [
        "df[100:110]"
      ],
      "metadata": {
        "id": "AUmWTPnpOpcB"
      },
      "id": "AUmWTPnpOpcB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the first 3 rows of data from the variable df."
      ],
      "metadata": {
        "id": "2dN-qdFNARJq"
      },
      "id": "2dN-qdFNARJq"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "7sowj7LqPjBh"
      },
      "id": "7sowj7LqPjBh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the rows of data from 2010 to 2015 from the variable df."
      ],
      "metadata": {
        "id": "-9rkYReHAuUj"
      },
      "id": "-9rkYReHAuUj"
    },
    {
      "cell_type": "code",
      "source": [
        "df[2010:2016]"
      ],
      "metadata": {
        "id": "1EU8c4a7PpxZ"
      },
      "id": "1EU8c4a7PpxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find out some general characteristics of the columns."
      ],
      "metadata": {
        "id": "D3lp0JKPA9Zk"
      },
      "id": "D3lp0JKPA9Zk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b925401d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-05T13:39:43.134853Z",
          "start_time": "2023-05-05T13:39:43.110770Z"
        },
        "id": "b925401d"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.StockCode.loc[0])"
      ],
      "metadata": {
        "id": "DBAxBOagmtua"
      },
      "id": "DBAxBOagmtua",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the data types in each column, whether all data is filled, and how much memory the data occupies in RAM."
      ],
      "metadata": {
        "id": "ZUTkv8akBRQH"
      },
      "id": "ZUTkv8akBRQH"
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "lBpo0vabnf7Z"
      },
      "id": "lBpo0vabnf7Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's start the analysis!"
      ],
      "metadata": {
        "id": "lwjSNi1tBnN7"
      },
      "id": "lwjSNi1tBnN7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What countries are represented in this dataset?"
      ],
      "metadata": {
        "id": "jrjr-mN1Bzhd"
      },
      "id": "jrjr-mN1Bzhd"
    },
    {
      "cell_type": "code",
      "source": [
        "df.Country"
      ],
      "metadata": {
        "id": "UVFNe3EF9hXM"
      },
      "id": "UVFNe3EF9hXM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's **count how many times each country** is represented."
      ],
      "metadata": {
        "id": "3SyNlY529htx"
      },
      "id": "3SyNlY529htx"
    },
    {
      "cell_type": "code",
      "source": [
        "df.Country.value_counts()"
      ],
      "metadata": {
        "id": "qKZQVzw6Rt9A"
      },
      "id": "qKZQVzw6Rt9A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the **last 5 countries**."
      ],
      "metadata": {
        "id": "f3LEha4kCLqz"
      },
      "id": "f3LEha4kCLqz"
    },
    {
      "cell_type": "code",
      "source": [
        "df.Country.value_counts()[-5:]"
      ],
      "metadata": {
        "id": "EDE4a2ctovrD"
      },
      "id": "EDE4a2ctovrD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the top 10 countries by the number of rows in the variable df, along with the corresponding number of rows."
      ],
      "metadata": {
        "id": "4yZ2VPSvCvf8"
      },
      "id": "4yZ2VPSvCvf8"
    },
    {
      "cell_type": "code",
      "source": [
        "df.Country.value_counts()[:10]"
      ],
      "metadata": {
        "id": "uNQwXpFAmAzj"
      },
      "id": "uNQwXpFAmAzj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are **the most popular products** in the store?"
      ],
      "metadata": {
        "id": "tXU8AsRPC6cc"
      },
      "id": "tXU8AsRPC6cc"
    },
    {
      "cell_type": "code",
      "source": [
        "df.StockCode.value_counts()"
      ],
      "metadata": {
        "id": "XTPadYRQYHTW"
      },
      "id": "XTPadYRQYHTW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data filtering\n",
        "\n",
        "It would be interesting to find out what this popular product is. Let's take a look at the description."
      ],
      "metadata": {
        "id": "neaR_z4tDSqw"
      },
      "id": "neaR_z4tDSqw"
    },
    {
      "cell_type": "code",
      "source": [
        "df.StockCode=='85123A'"
      ],
      "metadata": {
        "id": "mrdQKNDCpcM0"
      },
      "id": "mrdQKNDCpcM0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.StockCode=='85123A']"
      ],
      "metadata": {
        "id": "5AJdAhUNYPzD"
      },
      "id": "5AJdAhUNYPzD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the descriptions are different. Let's check what descriptions exist and how many there are."
      ],
      "metadata": {
        "id": "6CWD56wrDoCS"
      },
      "id": "6CWD56wrDoCS"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.StockCode=='85123A'].Description.value_counts()"
      ],
      "metadata": {
        "id": "2p5W4QnN8n0x"
      },
      "id": "2p5W4QnN8n0x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are data entries where something went wrong (there are few of them, and they differ from the majority). We can manually correct or clean them if they are not needed for the analysis.\n",
        "\n",
        "Let's take a look at the other records."
      ],
      "metadata": {
        "id": "I94_awJNEG3d"
      },
      "id": "I94_awJNEG3d"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.StockCode==22423]"
      ],
      "metadata": {
        "id": "W74biQZKsUE6"
      },
      "id": "W74biQZKsUE6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Something went wrong. It seems that the value has a different type. How can we check this?"
      ],
      "metadata": {
        "id": "Nz1zFwi3ETpZ"
      },
      "id": "Nz1zFwi3ETpZ"
    },
    {
      "cell_type": "code",
      "source": [
        "df.StockCode.value_counts().index"
      ],
      "metadata": {
        "id": "A0Aol9a5ai57"
      },
      "id": "A0Aol9a5ai57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the value 22423 is surrounded by quotes, which means it is a string and NOT a number. In Python, values in quotes are always strings."
      ],
      "metadata": {
        "id": "rIeydxXEEtUK"
      },
      "id": "rIeydxXEEtUK"
    },
    {
      "cell_type": "code",
      "source": [
        "type(22423), type('22423'), type('85123A')"
      ],
      "metadata": {
        "id": "ggKTrRTda-_g"
      },
      "id": "ggKTrRTda-_g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "22423 != '22423'"
      ],
      "metadata": {
        "id": "lsVHdbn0-DAg"
      },
      "id": "lsVHdbn0-DAg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's why our data wasn't filtered. Let's fix that!"
      ],
      "metadata": {
        "id": "6dEAAzwYFKF5"
      },
      "id": "6dEAAzwYFKF5"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.StockCode=='22423']"
      ],
      "metadata": {
        "id": "j1Gb1JmJb4_G"
      },
      "id": "j1Gb1JmJb4_G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find out what descriptions the purchased goods with a **StockCode** value of **22423** have, and how many times each of the description values occurs?"
      ],
      "metadata": {
        "id": "20OnRrrmJMX7"
      },
      "id": "20OnRrrmJMX7"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.StockCode=='22423'].Description.value_counts()"
      ],
      "metadata": {
        "id": "k7zYVfErmUt9"
      },
      "id": "k7zYVfErmUt9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjw57r3DKAdz"
      },
      "id": "wjw57r3DKAdz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the mean for the United Kingdom"
      ],
      "metadata": {
        "id": "iQiDCexYJxlx"
      },
      "id": "iQiDCexYJxlx"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='United Kingdom'][df.StockCode=='22423'].UnitPrice.mean()"
      ],
      "metadata": {
        "id": "Q_FhzzyC_SML"
      },
      "id": "Q_FhzzyC_SML",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the mean for France"
      ],
      "metadata": {
        "id": "gBe27dLkJ0To"
      },
      "id": "gBe27dLkJ0To"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='France'][df.StockCode=='22423'].UnitPrice.mean()"
      ],
      "metadata": {
        "id": "K7l4n4ux_o15"
      },
      "id": "K7l4n4ux_o15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the mean for Germany"
      ],
      "metadata": {
        "id": "vUquf0hvJ1PM"
      },
      "id": "vUquf0hvJ1PM"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='Germany'][df.StockCode=='22423'].UnitPrice.mean()"
      ],
      "metadata": {
        "id": "PgIhatFN_tdC"
      },
      "id": "PgIhatFN_tdC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find out what the average price of goods with a **StockCode** value of **22423** is in **Spain**"
      ],
      "metadata": {
        "id": "y4dYpsN8KMhP"
      },
      "id": "y4dYpsN8KMhP"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='Spain'][df.StockCode=='22423'].UnitPrice.mean()"
      ],
      "metadata": {
        "id": "alcvN-gCmYcb"
      },
      "id": "alcvN-gCmYcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the average across all selected countries at once"
      ],
      "metadata": {
        "id": "rq8h3wDAKWQE"
      },
      "id": "rq8h3wDAKWQE"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country.isin(['Germany', 'France', 'United Kingdom'])][df.StockCode=='22423'][['Country', 'UnitPrice']]"
      ],
      "metadata": {
        "id": "pmiXkxxyBgar"
      },
      "id": "pmiXkxxyBgar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to simplify the code. To avoid writing a large piece of code every time, let's store this structure in a variable:"
      ],
      "metadata": {
        "id": "NSgwKjodKwnF"
      },
      "id": "NSgwKjodKwnF"
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[df.Country.isin(['Germany', 'France', 'United Kingdom'])][df.StockCode=='22423'][['Country', 'UnitPrice']]"
      ],
      "metadata": {
        "id": "BcFgnD-JDQQI"
      },
      "id": "BcFgnD-JDQQI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Country', 'UnitPrice']]"
      ],
      "metadata": {
        "id": "Cp7-641U-OLM"
      },
      "id": "Cp7-641U-OLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the country and its average purchase value of the product."
      ],
      "metadata": {
        "id": "N-WlbHAtDs6N"
      },
      "id": "N-WlbHAtDs6N"
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered"
      ],
      "metadata": {
        "id": "ubC53mMnD2ih"
      },
      "id": "ubC53mMnD2ih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's GROUP THE DATA BY COUNTRY! Then we will calculate the aggregate function"
      ],
      "metadata": {
        "id": "RxyJOVhALdlN"
      },
      "id": "RxyJOVhALdlN"
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.groupby('Country').mean()"
      ],
      "metadata": {
        "id": "q3tSOuiTEDzV"
      },
      "id": "q3tSOuiTEDzV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without using a variable, it could look like this. Just writing everything directly for our variable df"
      ],
      "metadata": {
        "id": "v9DGzcheLwDu"
      },
      "id": "v9DGzcheLwDu"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country.isin(['Germany', 'France', 'United Kingdom'])][df.StockCode=='22423'][['Country', 'UnitPrice']].groupby('Country').mean()"
      ],
      "metadata": {
        "id": "WGswQMBfGS6D"
      },
      "id": "WGswQMBfGS6D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or like this"
      ],
      "metadata": {
        "id": "clGLscibGjhV"
      },
      "id": "clGLscibGjhV"
    },
    {
      "cell_type": "code",
      "source": [
        "df[\n",
        "    df.Country.isin(['Germany', 'France', 'United Kingdom'])\n",
        "  ][df.StockCode=='22423'].groupby('Country').UnitPrice.mean()"
      ],
      "metadata": {
        "id": "4o44yE2WGlN-"
      },
      "id": "4o44yE2WGlN-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the average price of ALL products in the countries Germany, France, and the United Kingdom?"
      ],
      "metadata": {
        "id": "ztCtPv-8MELa"
      },
      "id": "ztCtPv-8MELa"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country.isin(['Germany', 'France', 'United Kingdom'])].groupby('Country').UnitPrice.mean()"
      ],
      "metadata": {
        "id": "x5O80guEmitv"
      },
      "id": "x5O80guEmitv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data sorting\n",
        "\n",
        "What is the cheapest product that is purchased in France?"
      ],
      "metadata": {
        "id": "efW0lOsSG9Vx"
      },
      "id": "efW0lOsSG9Vx"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='France'].sort_values(by='StockCode') #This is not enough! By which field do you want to sort?"
      ],
      "metadata": {
        "id": "88u9_ZLNHGW6"
      },
      "id": "88u9_ZLNHGW6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='France'].sort_values(by='UnitPrice')"
      ],
      "metadata": {
        "id": "VW6SQ56JHLun"
      },
      "id": "VW6SQ56JHLun",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual entries are not very interesting to us. Let's remove them from this analysis"
      ],
      "metadata": {
        "id": "qRrmb4CTHU-y"
      },
      "id": "qRrmb4CTHU-y"
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.Country=='France'][df.StockCode!='M'].sort_values(by='UnitPrice')"
      ],
      "metadata": {
        "id": "aTsN2Bg0Hbq2"
      },
      "id": "aTsN2Bg0Hbq2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save this DataFrame in a variable so that we can work with it another time"
      ],
      "metadata": {
        "id": "3YpjIXynHqhx"
      },
      "id": "3YpjIXynHqhx"
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr_price_sorted = df[df.Country=='France'][df.StockCode!='M'].sort_values(by='UnitPrice')"
      ],
      "metadata": {
        "id": "UPVwjdlfHrJD"
      },
      "id": "UPVwjdlfHrJD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's sort in descending order:"
      ],
      "metadata": {
        "id": "X3WrDjxaK0OB"
      },
      "id": "X3WrDjxaK0OB"
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr_price_sorted.sort_values(by='UnitPrice', ascending=False).iloc[0]"
      ],
      "metadata": {
        "id": "k43_ribOK3jZ"
      },
      "id": "k43_ribOK3jZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr_price_sorted"
      ],
      "metadata": {
        "id": "MuZINdqZwrDn"
      },
      "id": "MuZINdqZwrDn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find the product that was purchased in the largest quantity in the DataFrame df_fr_price_sorted. We'll display the product and write a conclusion about which product it is (with which InvoiceId, StockCode)."
      ],
      "metadata": {
        "id": "2yQw5QUiNVJY"
      },
      "id": "2yQw5QUiNVJY"
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr_price_sorted.sort_values('Quantity', ascending=False).iloc[0]"
      ],
      "metadata": {
        "id": "KrOfMMyyU99K"
      },
      "id": "KrOfMMyyU99K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/My Drive/mydata.csv', index=False)"
      ],
      "metadata": {
        "id": "Hf9nBw4KXAEQ"
      },
      "id": "Hf9nBw4KXAEQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr_price_sorted.to_csv('/content/drive/My Drive/online_retail_Fr_UnitPrice_sorted.csv')"
      ],
      "metadata": {
        "id": "qAB-KXe4H5Bu"
      },
      "id": "qAB-KXe4H5Bu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.read_csv('/content/drive/My Drive/online_retail_Fr_UnitPrice_sorted.csv', index_col=0)"
      ],
      "metadata": {
        "id": "zEf2CQHdIB8J"
      },
      "id": "zEf2CQHdIB8J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "4MwKlCoXIHae"
      },
      "id": "4MwKlCoXIHae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention! This file exists only in this session! You can either save it directly to your Google Drive or download the file locally and upload it to Google Drive manually."
      ],
      "metadata": {
        "id": "av7X14FWIeq0"
      },
      "id": "av7X14FWIeq0"
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr_price_sorted.to_csv('/content/drive/MyDrive/online_retail_Fr_UnitPrice_sorted.csv')"
      ],
      "metadata": {
        "id": "u-BZIJyDIpiV"
      },
      "id": "u-BZIJyDIpiV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Descriptive Analysis\n",
        "1. Sales Overview:"
      ],
      "metadata": {
        "id": "sDVOC1TBUaAa"
      },
      "id": "sDVOC1TBUaAa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total revenue\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "total_revenue = df['TotalRevenue'].sum()\n",
        "\n",
        "print(f\"Total sales revenue generated in the dataset: £{total_revenue:.2f}\")"
      ],
      "metadata": {
        "id": "uhJxi4I_RY8C"
      },
      "id": "uhJxi4I_RY8C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How many unique products were sold?\n",
        "# Count unique products sold based on the 'StockCode' column\n",
        "unique_products = df['StockCode'].nunique()\n",
        "\n",
        "print(f\"Number of unique products sold: {unique_products}\")"
      ],
      "metadata": {
        "id": "2HJI8LAuTjS-"
      },
      "id": "2HJI8LAuTjS-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Customer Insights:\n",
        "\n",
        "  2.1. How many unique customers are there in the dataset?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BpvTyJ-hUlZg"
      },
      "id": "BpvTyJ-hUlZg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unique customers based on the 'CustomerID' column\n",
        "# First, ensure that CustomerID is not null\n",
        "unique_customers = df['CustomerID'].nunique()\n",
        "\n",
        "print(f\"Number of unique customers in the dataset: {unique_customers}\")"
      ],
      "metadata": {
        "id": "x6knBz6AUGPP"
      },
      "id": "x6knBz6AUGPP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2.2. What is the average order value for customers?\n"
      ],
      "metadata": {
        "id": "yGlWIu-xUwpU"
      },
      "id": "yGlWIu-xUwpU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by 'InvoiceNo' and calculate the sum of total revenue for each order\n",
        "order_values = df.groupby('InvoiceNo')['TotalRevenue'].sum()\n",
        "\n",
        "# Calculate the average order value\n",
        "average_order_value = order_values.mean()\n",
        "\n",
        "print(f\"Average order value for customers: £{average_order_value:.2f}\")"
      ],
      "metadata": {
        "id": "qJ3_bk6UU3BF"
      },
      "id": "qJ3_bk6UU3BF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Product Analysis:\n",
        "\n",
        "  3.1. What are the top-selling products by quantity sold?"
      ],
      "metadata": {
        "id": "sQL0feO2VHn1"
      },
      "id": "sQL0feO2VHn1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'Quantity' is negative or NaN\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "# Group by 'StockCode' or 'Description' and calculate total quantity sold\n",
        "top_selling_products = df.groupby('Description')['Quantity'].sum().reset_index()\n",
        "\n",
        "# Sort the results by quantity sold in descending order\n",
        "top_selling_products = top_selling_products.sort_values(by='Quantity', ascending=False)\n",
        "\n",
        "# Display the top 10 selling products\n",
        "top_10_products = top_selling_products.head(10)\n",
        "\n",
        "print(\"Top-selling products by quantity sold:\")\n",
        "print(top_10_products)"
      ],
      "metadata": {
        "id": "_g8uKUA6VNb-"
      },
      "id": "_g8uKUA6VNb-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  3.2. Which products have the highest revenue?"
      ],
      "metadata": {
        "id": "eFyGvZ_SVhJa"
      },
      "id": "eFyGvZ_SVhJa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by 'Description' and calculate total revenue\n",
        "revenue_by_product = df.groupby('Description')['TotalRevenue'].sum().reset_index()\n",
        "\n",
        "# Sort the results by revenue in descending order\n",
        "revenue_by_product = revenue_by_product.sort_values(by='TotalRevenue', ascending=False)\n",
        "\n",
        "# Display the top 10 products by revenue\n",
        "top_revenue_products = revenue_by_product.head(10)\n",
        "\n",
        "print(\"Products with the highest revenue:\")\n",
        "print(top_revenue_products)"
      ],
      "metadata": {
        "id": "29W6ib6PWGUi"
      },
      "id": "29W6ib6PWGUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temporal Analysis\n",
        "4. Sales Trends:\n",
        "\n",
        "  4.1. How do sales figures vary month over month?"
      ],
      "metadata": {
        "id": "0QShpHz2WLb9"
      },
      "id": "0QShpHz2WLb9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Create a new DataFrame with month and year\n",
        "df['Month'] = df['InvoiceDate'].dt.to_period('M')\n",
        "\n",
        "# Group by month and calculate total revenue\n",
        "monthly_sales = df.groupby('Month')['TotalRevenue'].sum().reset_index()\n",
        "\n",
        "# Convert 'Month' back to datetime for plotting\n",
        "monthly_sales['Month'] = monthly_sales['Month'].dt.to_timestamp()\n",
        "\n",
        "# Display the monthly sales\n",
        "print(\"Monthly sales revenue:\")\n",
        "print(monthly_sales)\n",
        "\n",
        "# Plotting the monthly sales figures\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(monthly_sales['Month'], monthly_sales['TotalRevenue'], marker='o')\n",
        "plt.title('Monthly Sales Revenue')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Revenue (£)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_FTjdOMkWWFG"
      },
      "id": "_FTjdOMkWWFG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  4.2. What are the peak sales periods (days, weeks, or months) in the dataset?"
      ],
      "metadata": {
        "id": "fRAItXv7WWa9"
      },
      "id": "fRAItXv7WWa9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by day and calculate total revenue\n",
        "daily_sales = df.groupby(df['InvoiceDate'].dt.date)['TotalRevenue'].sum().reset_index()\n",
        "daily_sales.columns = ['Date', 'TotalRevenue']\n",
        "\n",
        "# Group by week and calculate total revenue\n",
        "weekly_sales = df.resample('W-Mon', on='InvoiceDate')['TotalRevenue'].sum().reset_index()\n",
        "weekly_sales.columns = ['Week', 'TotalRevenue']\n",
        "\n",
        "# Group by month and calculate total revenue\n",
        "monthly_sales = df.resample('M', on='InvoiceDate')['TotalRevenue'].sum().reset_index()\n",
        "monthly_sales.columns = ['Month', 'TotalRevenue']\n",
        "\n",
        "# Identify peak sales periods\n",
        "peak_daily = daily_sales.loc[daily_sales['TotalRevenue'].idxmax()]\n",
        "peak_weekly = weekly_sales.loc[weekly_sales['TotalRevenue'].idxmax()]\n",
        "peak_monthly = monthly_sales.loc[monthly_sales['TotalRevenue'].idxmax()]\n",
        "\n",
        "# Display peak periods\n",
        "print(f\"Peak sales day: {peak_daily['Date']} with revenue: £{peak_daily['TotalRevenue']:.2f}\")\n",
        "print(f\"Peak sales week: {peak_weekly['Week']} with revenue: £{peak_weekly['TotalRevenue']:.2f}\")\n",
        "print(f\"Peak sales month: {peak_monthly['Month']} with revenue: £{peak_monthly['TotalRevenue']:.2f}\")\n",
        "\n",
        "# Optional: Plotting the results for visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(daily_sales['Date'], daily_sales['TotalRevenue'], label='Daily Sales', marker='o', alpha=0.7)\n",
        "plt.title('Daily Sales Revenue')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Revenue (£)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(weekly_sales['Week'], weekly_sales['TotalRevenue'], label='Weekly Sales', marker='o', alpha=0.7)\n",
        "plt.title('Weekly Sales Revenue')\n",
        "plt.xlabel('Week')\n",
        "plt.ylabel('Total Revenue (£)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(monthly_sales['Month'], monthly_sales['TotalRevenue'], label='Monthly Sales', marker='o', alpha=0.7)\n",
        "plt.title('Monthly Sales Revenue')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Revenue (£)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eqoKD_clW2XB"
      },
      "id": "eqoKD_clW2XB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Customer Purchase Patterns:\n",
        "\n",
        "  5.1. How often do customers make repeat purchases?"
      ],
      "metadata": {
        "id": "TTgKLbccW-Qd"
      },
      "id": "TTgKLbccW-Qd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame to understand its structure\n",
        "print(df.head())\n",
        "\n",
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Group by 'CustomerID' and count the number of unique invoices per customer\n",
        "repeat_purchases = df.groupby('CustomerID')['InvoiceNo'].nunique().reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "repeat_purchases.columns = ['CustomerID', 'NumUniquePurchases']\n",
        "\n",
        "# Count the frequency of repeat purchases\n",
        "repeat_counts = repeat_purchases['NumUniquePurchases'].value_counts().sort_index()\n",
        "\n",
        "# Display the number of customers making repeat purchases\n",
        "print(\"Frequency of Repeat Purchases:\")\n",
        "print(repeat_counts)\n",
        "\n",
        "# Plotting the distribution of repeat purchases\n",
        "plt.figure(figsize=(10, 6))\n",
        "repeat_counts.plot(kind='bar')\n",
        "plt.title('Distribution of Repeat Purchases by Number of Unique Purchases')\n",
        "plt.xlabel('Number of Unique Purchases')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate percentage of customers with repeat purchases\n",
        "num_repeat_customers = repeat_counts[repeat_counts.index > 1].sum()\n",
        "total_customers = repeat_purchases['CustomerID'].nunique()\n",
        "percentage_repeat_customers = (num_repeat_customers / total_customers) * 100\n",
        "\n",
        "print(f\"Percentage of customers making repeat purchases: {percentage_repeat_customers:.2f}%\")"
      ],
      "metadata": {
        "id": "8L3Z1-GWXMQY"
      },
      "id": "8L3Z1-GWXMQY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  5.2. What is the average time between a customer's first and last purchase?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fvvc0NjvXXHH"
      },
      "id": "Fvvc0NjvXXHH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Group by 'CustomerID' and get the first and last purchase date\n",
        "customer_purchase_dates = df.groupby('CustomerID')['InvoiceDate'].agg(['min', 'max']).reset_index()\n",
        "\n",
        "# Calculate the time difference between first and last purchase\n",
        "customer_purchase_dates['TimeDifference'] = customer_purchase_dates['max'] - customer_purchase_dates['min']\n",
        "\n",
        "# Calculate the average time difference\n",
        "average_time_difference = customer_purchase_dates['TimeDifference'].mean()\n",
        "\n",
        "# Display the average time difference in days\n",
        "print(f\"Average time between a customer's first and last purchase: {average_time_difference.days:.2f} days\")"
      ],
      "metadata": {
        "id": "91HvNwlWZLWz"
      },
      "id": "91HvNwlWZLWz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geographic Analysis\n",
        "6. Sales by Country:\n",
        "  \n",
        "  6.1. Which countries generate the most revenue?\n"
      ],
      "metadata": {
        "id": "5Gl9KRfKU8sO"
      },
      "id": "5Gl9KRfKU8sO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by country and calculate total revenue\n",
        "country_revenue = df.groupby('Country')['TotalRevenue'].sum().reset_index()\n",
        "\n",
        "# Sort the countries by revenue in descending order\n",
        "country_revenue = country_revenue.sort_values(by='TotalRevenue', ascending=False)\n",
        "\n",
        "# Display the top countries by revenue\n",
        "print(\"Countries generating the most revenue:\")\n",
        "print(country_revenue.head(10))\n",
        "\n",
        "# Plotting the revenue by country for visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(country_revenue['Country'][:10], country_revenue['TotalRevenue'][:10], color='skyblue')\n",
        "plt.title('Top 10 Countries by Revenue')\n",
        "plt.xlabel('Total Revenue (£)')\n",
        "plt.ylabel('Country')\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u69HwF4EYfDk"
      },
      "id": "u69HwF4EYfDk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  6.2. What is the average order value per country?\n",
        "\n"
      ],
      "metadata": {
        "id": "-TbDch_2YfVz"
      },
      "id": "-TbDch_2YfVz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by country to calculate total revenue and number of unique orders\n",
        "country_summary = df.groupby('Country').agg(\n",
        "    TotalRevenue=('TotalRevenue', 'sum'),\n",
        "    UniqueOrders=('InvoiceNo', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Calculate the average order value per country\n",
        "country_summary['AverageOrderValue'] = country_summary['TotalRevenue'] / country_summary['UniqueOrders']\n",
        "\n",
        "# Display the average order value per country\n",
        "print(\"Average Order Value per Country:\")\n",
        "print(country_summary[['Country', 'AverageOrderValue']].sort_values(by='AverageOrderValue', ascending=False))\n",
        "\n",
        "# Optional: Plotting the average order value per country for visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(country_summary['Country'], country_summary['AverageOrderValue'], color='lightgreen')\n",
        "plt.title('Average Order Value per Country')\n",
        "plt.xlabel('Average Order Value (£)')\n",
        "plt.ylabel('Country')\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_YBcFfS-YiHu"
      },
      "id": "_YBcFfS-YiHu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customer Behavior\n",
        "7. Segmentation:\n",
        "\n",
        "  7.1. Can we segment customers based on their purchasing behavior (e.g., frequent vs. infrequent buyers)?"
      ],
      "metadata": {
        "id": "BUHFleGdYihl"
      },
      "id": "BUHFleGdYihl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by customer and calculate relevant metrics\n",
        "customer_segments = df.groupby('CustomerID').agg(\n",
        "    NumPurchases=('InvoiceNo', 'nunique'),\n",
        "    TotalSpent=('TotalRevenue', 'sum'),\n",
        "    LastPurchaseDate=('InvoiceDate', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# Calculate recency in days\n",
        "current_date = df['InvoiceDate'].max()  # Get the most recent date in the dataset\n",
        "customer_segments['Recency'] = (current_date - customer_segments['LastPurchaseDate']).dt.days\n",
        "\n",
        "# Define segments based on purchasing behavior\n",
        "def segment_customers(row):\n",
        "    if row['NumPurchases'] >= 10:\n",
        "        return 'Frequent Buyer'\n",
        "    elif row['NumPurchases'] >= 3:\n",
        "        return 'Moderate Buyer'\n",
        "    else:\n",
        "        return 'Infrequent Buyer'\n",
        "\n",
        "customer_segments['Segment'] = customer_segments.apply(segment_customers, axis=1)\n",
        "\n",
        "# Display segmented customers\n",
        "print(\"Customer Segmentation:\")\n",
        "print(customer_segments[['CustomerID', 'NumPurchases', 'TotalSpent', 'Recency', 'Segment']].head(10))\n",
        "\n",
        "# Optional: Visualize the segments\n",
        "plt.figure(figsize=(10, 6))\n",
        "customer_segments['Segment'].value_counts().plot(kind='bar', color='lightblue')\n",
        "plt.title('Customer Segmentation by Purchasing Behavior')\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QmYk3W33YmJn"
      },
      "id": "QmYk3W33YmJn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  7.2. How does customer behavior vary by country or region?\n"
      ],
      "metadata": {
        "id": "I1fQzp_fYmo_"
      },
      "id": "I1fQzp_fYmo_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Calculate total revenue for each transaction\n",
        "df['TotalRevenue'] = df['UnitPrice'] * df['Quantity']\n",
        "\n",
        "# Group by country to calculate total revenue, number of unique customers, and average order value\n",
        "country_summary = df.groupby('Country').agg(\n",
        "    TotalRevenue=('TotalRevenue', 'sum'),\n",
        "    UniqueCustomers=('CustomerID', 'nunique'),\n",
        "    NumPurchases=('InvoiceNo', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Calculate average order value (AOV)\n",
        "country_summary['AverageOrderValue'] = country_summary['TotalRevenue'] / country_summary['NumPurchases']\n",
        "\n",
        "# Sort countries by total revenue for better visualization\n",
        "country_summary = country_summary.sort_values(by='TotalRevenue', ascending=False)\n",
        "\n",
        "# Display the summary\n",
        "print(\"Customer Behavior by Country:\")\n",
        "print(country_summary)\n",
        "\n",
        "# Visualize total revenue by country\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(country_summary['Country'], country_summary['TotalRevenue'], color='lightblue')\n",
        "plt.title('Total Revenue by Country')\n",
        "plt.xlabel('Total Revenue (£)')\n",
        "plt.ylabel('Country')\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize average order value by country\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(country_summary['Country'], country_summary['AverageOrderValue'], color='lightgreen')\n",
        "plt.title('Average Order Value by Country')\n",
        "plt.xlabel('Average Order Value (£)')\n",
        "plt.ylabel('Country')\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize number of unique customers by country\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(country_summary['Country'], country_summary['UniqueCustomers'], color='salmon')\n",
        "plt.title('Number of Unique Customers by Country')\n",
        "plt.xlabel('Number of Unique Customers')\n",
        "plt.ylabel('Country')\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uw5kn3ZqYpZB"
      },
      "id": "uw5kn3ZqYpZB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Abandoned Carts:\n",
        "\n",
        "Are there indications of abandoned carts or incomplete purchases in the data?"
      ],
      "metadata": {
        "id": "iPEBKzJUYptq"
      },
      "id": "iPEBKzJUYptq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "df = df[(df['UnitPrice'] > 0) & (df['Quantity'] > 0)]\n",
        "\n",
        "# Count unique items per invoice\n",
        "invoice_counts = df.groupby('InvoiceNo').agg(\n",
        "    NumItems=('StockCode', 'count'),\n",
        "    TotalRevenue=('TotalRevenue', 'sum'),\n",
        "    UniqueCustomers=('CustomerID', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Potential indicators of abandoned carts\n",
        "abandoned_carts = invoice_counts[(invoice_counts['NumItems'] == 1) |\n",
        "                                  (invoice_counts['TotalRevenue'] == 0)]\n",
        "\n",
        "# Display abandoned carts\n",
        "print(\"Potential Abandoned Carts or Incomplete Purchases:\")\n",
        "print(abandoned_carts)\n",
        "\n",
        "# Visualizing potential abandoned carts\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(invoice_counts['NumItems'], bins=range(1, invoice_counts['NumItems'].max() + 2), alpha=0.7, color='orange', edgecolor='black')\n",
        "plt.axvline(x=1, color='red', linestyle='dashed', linewidth=2)\n",
        "plt.title('Number of Items per Invoice')\n",
        "plt.xlabel('Number of Items')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(range(1, invoice_counts['NumItems'].max() + 1))\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GnYbf-E1YtXn"
      },
      "id": "GnYbf-E1YtXn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product Performance\n",
        "9. Product Returns:\n",
        "\n",
        "  9.1. What is the return rate for different products?"
      ],
      "metadata": {
        "id": "RzANayi1Ytta"
      },
      "id": "RzANayi1Ytta"
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning: Remove any rows where 'Quantity' is zero or 'UnitPrice' is negative or NaN\n",
        "df = df[(df['Quantity'] != 0) & (df['UnitPrice'] > 0)]\n",
        "\n",
        "# Identify returns: Rows with negative quantities (indicating returns)\n",
        "returns = df[df['Quantity'] < 0]\n",
        "\n",
        "# Convert returns to positive for analysis\n",
        "returns['Quantity'] = returns['Quantity'].abs()\n",
        "\n",
        "# Group by product (StockCode) to calculate total sold and total returned\n",
        "sales = df.groupby('StockCode').agg(\n",
        "    TotalSold=('Quantity', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Group returns by product to calculate total returned\n",
        "returns_summary = returns.groupby('StockCode').agg(\n",
        "    TotalReturned=('Quantity', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Merge sales and returns dataframes\n",
        "return_rates = pd.merge(sales, returns_summary, on='StockCode', how='left').fillna(0)\n",
        "\n",
        "# Calculate return rate\n",
        "return_rates['ReturnRate'] = return_rates['TotalReturned'] / return_rates['TotalSold']\n",
        "\n",
        "# Sort return rates in descending order\n",
        "return_rates = return_rates.sort_values(by='ReturnRate', ascending=False)\n",
        "\n",
        "# Display return rates for the top 10 products\n",
        "print(\"Return Rates for Different Products:\")\n",
        "print(return_rates[['StockCode', 'TotalSold', 'TotalReturned', 'ReturnRate']].head(10))\n",
        "\n",
        "# Visualize return rates for the top 20 products\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(return_rates['StockCode'].astype(str).head(20), return_rates['ReturnRate'].head(20), color='lightcoral')\n",
        "plt.title('Return Rates for Different Products')\n",
        "plt.xlabel('Stock Code')\n",
        "plt.ylabel('Return Rate')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Number of return Rates for Different Products: {len(return_rates)}\")\n"
      ],
      "metadata": {
        "id": "pOCy_4QbYxLq"
      },
      "id": "pOCy_4QbYxLq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  9.2. Are there specific products that have a high incidence of returns?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZIxHOS1XYxdg"
      },
      "id": "ZIxHOS1XYxdg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Remove any rows where 'UnitPrice' or 'Quantity' is negative or NaN\n",
        "# Also handle missing values\n",
        "df = df[(df['Quantity'] != 0) & (df['UnitPrice'] > 0)]\n",
        "df.dropna(subset=['InvoiceNo', 'CustomerID'], inplace=True)\n",
        "\n",
        "# Identify returns: Rows with negative quantities (returns)\n",
        "returns = df[df['Quantity'] < 0]\n",
        "\n",
        "# Convert returns to positive for analysis\n",
        "returns['Quantity'] = returns['Quantity'].abs()\n",
        "\n",
        "# Group by product (StockCode) to calculate total sold\n",
        "sales = df.groupby('StockCode').agg(\n",
        "    TotalSold=('Quantity', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Group by product to calculate total returned\n",
        "returns_summary = returns.groupby('StockCode').agg(\n",
        "    TotalReturned=('Quantity', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Merge sales and returns dataframes\n",
        "return_rates = pd.merge(sales, returns_summary, on='StockCode', how='left').fillna(0)\n",
        "\n",
        "# Calculate return rate\n",
        "return_rates['ReturnRate'] = return_rates['TotalReturned'] / return_rates['TotalSold']\n",
        "\n",
        "# Identify products with high return rates (e.g., > 20%)\n",
        "high_return_threshold = 0.20\n",
        "high_return_products = return_rates[return_rates['ReturnRate'] > high_return_threshold]\n",
        "\n",
        "# Sort by return rate\n",
        "high_return_products = high_return_products.sort_values(by='ReturnRate', ascending=False)\n",
        "\n",
        "# Display high return products\n",
        "print(\"Products with High Return Rates (>20%):\")\n",
        "print(high_return_products[['StockCode', 'TotalSold', 'TotalReturned', 'ReturnRate']].head(10))\n",
        "\n",
        "# Visualize high return rates\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(high_return_products['StockCode'].astype(str).head(10), high_return_products['ReturnRate'].head(10), color='lightcoral')\n",
        "plt.title('Products with High Return Rates')\n",
        "plt.xlabel('Stock Code')\n",
        "plt.ylabel('Return Rate')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Number of products with high return rates: {len(high_return_products)}\")\n"
      ],
      "metadata": {
        "id": "0WZc09OdYzk3"
      },
      "id": "0WZc09OdYzk3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Seasonality:\n",
        "\n",
        "Are there seasonal trends in product sales (e.g., holiday spikes)?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DksVKtCEY0FP"
      },
      "id": "DksVKtCEY0FP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where 'InvoiceDate' or 'Quantity' is NaN and 'Quantity' is negative\n",
        "df.dropna(subset=['InvoiceDate', 'Quantity'], inplace=True)\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Create a new column for Month-Year\n",
        "df['MonthYear'] = df['InvoiceDate'].dt.to_period('M')\n",
        "\n",
        "# Group by Month-Year to get total sales\n",
        "monthly_sales = df.groupby('MonthYear').agg(\n",
        "    TotalSales=('Quantity', 'sum'),\n",
        "    TotalRevenue=('UnitPrice', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Visualizing Monthly Sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(monthly_sales['MonthYear'].astype(str), monthly_sales['TotalRevenue'], marker='o', color='blue')\n",
        "plt.title('Monthly Sales Revenue Over Time')\n",
        "plt.xlabel('Month-Year')\n",
        "plt.ylabel('Total Revenue')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualizing Monthly Sales Quantity\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(monthly_sales['MonthYear'].astype(str), monthly_sales['TotalSales'], marker='o', color='orange')\n",
        "plt.title('Monthly Sales Quantity Over Time')\n",
        "plt.xlabel('Month-Year')\n",
        "plt.ylabel('Total Quantity Sold')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sHoquy-KY2Ky"
      },
      "id": "sHoquy-KY2Ky",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predictive Analysis\n",
        "11. Forecasting:\n",
        "\n",
        "  11.1. What are the forecasts for future sales based on historical data?\n",
        "  "
      ],
      "metadata": {
        "id": "_8A4cfDkY2vG"
      },
      "id": "_8A4cfDkY2vG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where 'InvoiceDate' or 'Quantity' is NaN and 'Quantity' is negative\n",
        "df.dropna(subset=['InvoiceDate', 'Quantity'], inplace=True)\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Create a new column for Month-Year\n",
        "df['MonthYear'] = df['InvoiceDate'].dt.to_period('M')\n",
        "\n",
        "# Group by Month-Year to get total sales revenue\n",
        "monthly_sales = df.groupby('MonthYear').agg(\n",
        "    TotalRevenue=('UnitPrice', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Convert MonthYear to datetime for modeling\n",
        "monthly_sales['MonthYear'] = monthly_sales['MonthYear'].dt.to_timestamp()\n",
        "\n",
        "# Set MonthYear as the index\n",
        "monthly_sales.set_index('MonthYear', inplace=True)\n",
        "\n",
        "# Fit the ARIMA model (order can be adjusted based on data characteristics)\n",
        "model = ARIMA(monthly_sales['TotalRevenue'], order=(1, 1, 1))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Forecast future sales for the next 12 months\n",
        "forecast = model_fit.forecast(steps=12)\n",
        "\n",
        "# Create a new DataFrame for the forecasted values\n",
        "forecast_index = pd.date_range(start=monthly_sales.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')\n",
        "forecast_series = pd.Series(forecast, index=forecast_index)\n",
        "\n",
        "# Plot the historical sales and the forecasted sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(monthly_sales.index, monthly_sales['TotalRevenue'], label='Historical Sales', color='blue')\n",
        "plt.plot(forecast_series.index, forecast_series, label='Forecasted Sales', color='orange', linestyle='--')\n",
        "plt.title('Sales Forecast for the Next 12 Months')\n",
        "plt.xlabel('Month-Year')\n",
        "plt.ylabel('Total Revenue')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lxU_A_KJY4-T"
      },
      "id": "lxU_A_KJY4-T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.2. How can we predict future customer behavior based on past purchasing patterns?\n",
        "\n"
      ],
      "metadata": {
        "id": "07DVXU6TY5Mq"
      },
      "id": "07DVXU6TY5Mq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "df.dropna(subset=['InvoiceDate', 'Quantity'], inplace=True)\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Create a 'TotalAmount' column\n",
        "df['TotalAmount'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Create a reference date\n",
        "reference_date = df['InvoiceDate'].max() + pd.DateOffset(days=1)\n",
        "\n",
        "# RFM Calculation\n",
        "rfm_df = df.groupby('CustomerID').agg({\n",
        "    'InvoiceDate': lambda x: (reference_date - x.max()).days,\n",
        "    'InvoiceNo': 'count',\n",
        "    'TotalAmount': 'sum'\n",
        "}).rename(columns={\n",
        "    'InvoiceDate': 'Recency',\n",
        "    'InvoiceNo': 'Frequency',\n",
        "    'TotalAmount': 'Monetary'\n",
        "})\n",
        "\n",
        "# Scale the RFM data\n",
        "rfm_df_scaled = (rfm_df - rfm_df.mean()) / rfm_df.std()\n",
        "\n",
        "# Clustering with K-Means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "rfm_df['Cluster'] = kmeans.fit_predict(rfm_df_scaled)\n",
        "\n",
        "# Visualizing the segments\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=rfm_df, x='Recency', y='Monetary', hue='Cluster', palette='Set2')\n",
        "plt.title('Customer Segments based on RFM Analysis')\n",
        "plt.xlabel('Recency (Days Since Last Purchase)')\n",
        "plt.ylabel('Monetary Value ($)')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Predicting Future Behavior\n",
        "# Example: Analyze one segment and predict behavior\n",
        "cluster_0 = rfm_df[rfm_df['Cluster'] == 0]\n",
        "print(\"Cluster 0 Summary:\\n\", cluster_0.describe())"
      ],
      "metadata": {
        "id": "0FKg3BD8Y7Zk"
      },
      "id": "0FKg3BD8Y7Zk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operational Insights\n",
        "12. Inventory Management:\n",
        "  "
      ],
      "metadata": {
        "id": "QgLtVIObY7vG"
      },
      "id": "QgLtVIObY7vG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows and info about the dataset\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Data Cleaning: Remove rows with missing or zero quantity or negative prices\n",
        "df.dropna(subset=['Quantity', 'UnitPrice'], inplace=True)\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "\n",
        "# Create a new column for total sales amount\n",
        "df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Calculate total sales and average daily sales for each product\n",
        "sales_per_product = df.groupby('StockCode').agg({\n",
        "    'TotalSales': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceDate': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "# Calculate average daily sales\n",
        "# Assuming there are unique invoices per day, use the invoice date to calculate days\n",
        "days_active = (df['InvoiceDate'].max() - df['InvoiceDate'].min()).days + 1  # +1 to include last day\n",
        "sales_per_product['AverageDailySales'] = sales_per_product['Quantity'] / days_active\n",
        "\n",
        "# Assuming a lead time of 14 days for restocking and a safety stock of 20 units\n",
        "lead_time = 14\n",
        "safety_stock = 20\n",
        "\n",
        "# Calculate Reorder Point (ROP)\n",
        "sales_per_product['ReorderPoint'] = (sales_per_product['AverageDailySales'] * lead_time) + safety_stock\n",
        "\n",
        "# Simulate current inventory (for demonstration; in practice, this would come from your inventory records)\n",
        "# For this example, let's assume a random current inventory level between 0 and 150 for each product\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sales_per_product['CurrentInventory'] = np.random.randint(0, 150, size=len(sales_per_product))\n",
        "\n",
        "# Identify products at risk of stockouts\n",
        "sales_per_product['AtRiskOfStockout'] = sales_per_product['CurrentInventory'] < sales_per_product['ReorderPoint']\n",
        "\n",
        "# Filter products at risk\n",
        "at_risk_products = sales_per_product[sales_per_product['AtRiskOfStockout']]\n",
        "\n",
        "# Display products at risk of stockouts\n",
        "print(\"Products at Risk of Stockouts:\")\n",
        "print(at_risk_products[['StockCode', 'CurrentInventory', 'ReorderPoint', 'AverageDailySales']])\n",
        "\n",
        "# Visualizing the inventory levels and reorder points\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=at_risk_products, x='StockCode', y='ReorderPoint', color='lightblue', label='Reorder Point')\n",
        "sns.barplot(data=at_risk_products, x='StockCode', y='CurrentInventory', color='salmon', label='Current Inventory')\n",
        "plt.title('Inventory Levels vs. Reorder Points for Products at Risk of Stockouts')\n",
        "plt.xlabel('Product (StockCode)')\n",
        "plt.ylabel('Units')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DqypSqCfY9sD"
      },
      "id": "DqypSqCfY9sD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  12.1. What are the inventory needs based on sales data?\n"
      ],
      "metadata": {
        "id": "OrAfG0dxgXu4"
      },
      "id": "OrAfG0dxgXu4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows and info about the dataset\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Data Cleaning: Remove rows with missing or zero quantity or negative prices\n",
        "df.dropna(subset=['Quantity', 'UnitPrice'], inplace=True)\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "\n",
        "# Create a new column for total sales amount\n",
        "df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Calculate total sales and average daily sales for each product\n",
        "sales_per_product = df.groupby('StockCode').agg({\n",
        "    'TotalSales': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceDate': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "# Calculate average daily sales\n",
        "# Assuming there are unique invoices per day, use the invoice date to calculate days\n",
        "days_active = (df['InvoiceDate'].max() - df['InvoiceDate'].min()).days + 1  # +1 to include last day\n",
        "sales_per_product['AverageDailySales'] = sales_per_product['Quantity'] / days_active\n",
        "\n",
        "# Assuming a lead time of 14 days for restocking and a safety stock of 20 units\n",
        "lead_time = 14\n",
        "safety_stock = 20\n",
        "\n",
        "# Calculate Reorder Point (ROP)\n",
        "sales_per_product['ReorderPoint'] = (sales_per_product['AverageDailySales'] * lead_time) + safety_stock\n",
        "\n",
        "# Simulate current inventory (for demonstration; in practice, this would come from your inventory records)\n",
        "# For this example, let's assume a random current inventory level between 0 and 150 for each product\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sales_per_product['CurrentInventory'] = np.random.randint(0, 150, size=len(sales_per_product))\n",
        "\n",
        "# Calculate the inventory needs (how much to reorder)\n",
        "sales_per_product['InventoryNeeds'] = sales_per_product['ReorderPoint'] - sales_per_product['CurrentInventory']\n",
        "\n",
        "# Filter for products that need reordering\n",
        "inventory_needs = sales_per_product[sales_per_product['InventoryNeeds'] > 0]\n",
        "\n",
        "# Display inventory needs\n",
        "print(\"Inventory Needs Based on Sales Data:\")\n",
        "print(inventory_needs[['StockCode', 'CurrentInventory', 'ReorderPoint', 'InventoryNeeds']])\n",
        "\n",
        "# Visualizing Inventory Needs\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=inventory_needs, x='StockCode', y='InventoryNeeds', color='orange')\n",
        "plt.title('Inventory Needs for Products Based on Sales Data')\n",
        "plt.xlabel('Product (StockCode)')\n",
        "plt.ylabel('Inventory Needs (Units)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FjVOFcXrgXLv"
      },
      "id": "FjVOFcXrgXLv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.2. Which products are at risk of stockouts?\n",
        "\n"
      ],
      "metadata": {
        "id": "cgjbEvGpY979"
      },
      "id": "cgjbEvGpY979"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows and info about the dataset\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Data Cleaning: Remove rows with missing or zero quantity or negative prices\n",
        "df.dropna(subset=['Quantity', 'UnitPrice'], inplace=True)\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "\n",
        "# Create a new column for total sales amount\n",
        "df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Calculate total sales and average daily sales for each product\n",
        "sales_per_product = df.groupby('StockCode').agg({\n",
        "    'TotalSales': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceDate': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "# Calculate average daily sales\n",
        "# Assuming there are unique invoices per day, use the invoice date to calculate days\n",
        "days_active = (df['InvoiceDate'].max() - df['InvoiceDate'].min()).days + 1  # +1 to include last day\n",
        "sales_per_product['AverageDailySales'] = sales_per_product['Quantity'] / days_active\n",
        "\n",
        "# Assuming a lead time of 14 days for restocking and a safety stock of 20 units\n",
        "lead_time = 14\n",
        "safety_stock = 20\n",
        "\n",
        "# Calculate Reorder Point (ROP)\n",
        "sales_per_product['ReorderPoint'] = (sales_per_product['AverageDailySales'] * lead_time) + safety_stock\n",
        "\n",
        "# Simulate current inventory (for demonstration; in practice, this would come from your inventory records)\n",
        "# For this example, let's assume a random current inventory level between 0 and 150 for each product\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sales_per_product['CurrentInventory'] = np.random.randint(0, 150, size=len(sales_per_product))\n",
        "\n",
        "# Identify products at risk of stockouts\n",
        "sales_per_product['AtRiskOfStockout'] = sales_per_product['CurrentInventory'] < sales_per_product['ReorderPoint']\n",
        "\n",
        "# Filter products at risk\n",
        "at_risk_products = sales_per_product[sales_per_product['AtRiskOfStockout']]\n",
        "\n",
        "# Display products at risk of stockouts\n",
        "print(\"Products at Risk of Stockouts:\")\n",
        "print(at_risk_products[['StockCode', 'CurrentInventory', 'ReorderPoint', 'AverageDailySales']])\n",
        "\n",
        "# Visualizing the inventory levels and reorder points\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=at_risk_products, x='StockCode', y='ReorderPoint', color='lightblue', label='Reorder Point')\n",
        "sns.barplot(data=at_risk_products, x='StockCode', y='CurrentInventory', color='salmon', label='Current Inventory')\n",
        "plt.title('Inventory Levels vs. Reorder Points for Products at Risk of Stockouts')\n",
        "plt.xlabel('Product (StockCode)')\n",
        "plt.ylabel('Units')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LAf4En8UY_iG"
      },
      "id": "LAf4En8UY_iG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Customer Feedback (if applicable)\n",
        "13. Feedback Analysis:\n",
        "\n",
        "How do customer reviews (if available) correlate with sales figures?\n",
        "\n"
      ],
      "metadata": {
        "id": "Bmsw6i01Y_38"
      },
      "id": "Bmsw6i01Y_38"
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning: Remove rows with missing or zero quantity or negative prices\n",
        "df.dropna(subset=['Quantity', 'UnitPrice'], inplace=True)\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "\n",
        "# Create a new column for total sales amount\n",
        "df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Simulate average review scores (1 to 5) for each product\n",
        "np.random.seed(42)\n",
        "stock_codes = df['StockCode'].unique()\n",
        "review_scores = pd.DataFrame({\n",
        "    'StockCode': stock_codes,\n",
        "    'AverageReviewScore': np.random.uniform(1, 5, size=len(stock_codes))  # Random scores between 1 and 5\n",
        "})\n",
        "\n",
        "# Calculate total sales and average sales for each product\n",
        "sales_per_product = df.groupby('StockCode').agg({\n",
        "    'TotalSales': 'sum',\n",
        "    'Quantity': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Merge sales data with review scores\n",
        "merged_data = pd.merge(sales_per_product, review_scores, on='StockCode')\n",
        "\n",
        "# Calculate the correlation between average review scores and total sales\n",
        "correlation = merged_data['AverageReviewScore'].corr(merged_data['TotalSales'])\n",
        "print(f\"Correlation between Average Review Score and Total Sales: {correlation:.2f}\")\n",
        "\n",
        "# Visualizing the correlation\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=merged_data, x='AverageReviewScore', y='TotalSales', alpha=0.6)\n",
        "plt.title('Customer Reviews vs Total Sales')\n",
        "plt.xlabel('Average Review Score')\n",
        "plt.ylabel('Total Sales (in currency units)')\n",
        "plt.xlim(1, 5)  # Setting limits for better visualization\n",
        "plt.ylim(0, merged_data['TotalSales'].max() * 1.1)\n",
        "plt.grid(True)\n",
        "plt.axhline(0, color='grey', lw=0.8)\n",
        "plt.axvline(0, color='grey', lw=0.8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EV3WQfOLZBbZ"
      },
      "id": "EV3WQfOLZBbZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Quality and Integrity\n",
        "14. Data Quality Checks:\n",
        "\n",
        "  14.1. Are there missing values or duplicates in the dataset?\n",
        "  "
      ],
      "metadata": {
        "id": "1PAFlx6LZBvD"
      },
      "id": "1PAFlx6LZBvD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows and info about the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in each column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])  # Display only columns with missing values\n",
        "\n",
        "# Check for duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicate rows in the dataset: {duplicates}\")\n",
        "\n",
        "# Summary of the dataset\n",
        "print(f\"\\nTotal number of rows in the dataset: {len(df)}\")"
      ],
      "metadata": {
        "id": "EOJ1freoZDNy"
      },
      "id": "EOJ1freoZDNy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  14.2. How do missing values affect the overall analysis?\n",
        "\n",
        "**Missing values can significantly impact data analysis in several ways. Here are the key effects and considerations regarding how missing values affect the overall analysis:**\n",
        "\n",
        "**1. Loss of Information**\n",
        "\n",
        "*   **Reduction in Dataset Size:** When rows with missing values are removed, it reduces the overall size of the dataset, which can lead to loss of valuable information.\n",
        "\n",
        "*   **Bias in Analysis:** If the missing values are not randomly distributed (e.g., concentrated in certain groups), the analysis may become biased, leading to incorrect conclusions.\n",
        "\n",
        "\n",
        "**2. Impact on Statistical Validity**\n",
        "\n",
        "* **Decreased Statistical Power:**  Fewer data points can reduce the ability to detect true effects or relationships. This is particularly important in hypothesis testing.\n",
        "\n",
        "* **Altered Distribution:** Missing values can distort the distribution of the data, which can affect statistical analyses such as mean, median, standard deviation, etc.\n",
        "\n",
        "**3. Inaccuracy in Predictions**\n",
        "* **Model Performance:** Missing values can reduce the accuracy of predictive models. Most machine learning algorithms require complete datasets and may not perform well when faced with missing values.\n",
        "\n",
        "* **Imputation Issues:** Techniques used to fill in missing values (imputation) can introduce biases if not done properly, potentially skewing results.\n",
        "\n",
        "**4. Complexity in Data Analysis**\n",
        "\n",
        "* **Increased Complexity:** Handling missing data often adds complexity to the analysis process. Analysts must decide how to handle missing values (e.g., removal, imputation), which can complicate workflows and analyses.\n",
        "\n",
        "* **Different Approaches:** Different strategies for dealing with missing values (e.g., mean imputation, regression imputation, deletion) can yield different results, leading to inconsistencies.\n",
        "\n",
        "**5. Data Quality and Trustworthiness**\n",
        "\n",
        "* **Trust in Data:** A dataset with a high percentage of missing values may lead to skepticism about the reliability of the data, making it harder to draw actionable insights.\n",
        "\n",
        "* **Need for Transparency:** It's crucial to document how missing values were handled and their potential impact on the analysis, ensuring transparency in the analytical process.\n",
        "\n",
        "##Strategies to Handle Missing Values\n",
        "\n",
        "To mitigate the negative impacts of missing values, here are some common strategies:\n",
        "\n",
        "**1. Deletion:**\n",
        "\n",
        "* **Listwise Deletion:** Remove rows with missing values, which is simple but can lead to loss of data.\n",
        "\n",
        "* **Pairwise Deletion:** Analyze only the available data points for each specific analysis, which retains more data.\n",
        "\n",
        "**2. Imputation:**\n",
        "\n",
        "* **Mean/Median Imputation:** Replace missing values with the mean or median of the column.\n",
        "\n",
        "* **Regression Imputation:** Use regression models to predict and fill in missing values based on other variables.\n",
        "\n",
        "* **K-Nearest Neighbors (KNN):** Use the nearest neighbors to estimate missing values based on similar data points.\n",
        "\n",
        "**3. Using Algorithms that Support Missing Values:**\n",
        "Some machine learning algorithms can handle missing values natively, such as decision trees and random forests.\n",
        "\n",
        "**4. Data Collection Improvements:**\n",
        "Enhancing data collection processes to minimize the occurrence of missing values in the future.\n",
        "\n",
        "##Conclusion\n",
        "\n",
        "Missing values can substantially influence the outcome of data analysis, making it crucial to address them appropriately.\n",
        "\n",
        "Understanding their impact allows analysts to make informed decisions on how to handle missing data, ensuring that the resulting analysis is robust and reliable.\n",
        "\n",
        "Taking the time to explore and manage missing values properly can enhance the quality of insights drawn from the data."
      ],
      "metadata": {
        "id": "X21y86-jZDeg"
      },
      "id": "X21y86-jZDeg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary Insights\n",
        "\n",
        "\n",
        "Total Sales Revenue: 8911407.904\n",
        "\n",
        "Top Selling Product: PAPER CRAFT , LITTLE BIRDIE\n",
        "\n",
        "Top Product Percentage of Revenue: 0.908891174913499\n",
        "\n",
        "Unique Customers: 4338\n",
        "\n",
        "Average Order Value: 480.86595639974104\n",
        "\n",
        "Top Countries Revenue: {'United Kingdom': 7308391.5540000005, 'Netherlands': 285446.34, 'EIRE': 265545.9}\n",
        "\n",
        "Repeat Purchase Percentage: 98.3633010603965\n",
        "\n",
        "At Risk Stockout Products (more in table below: use new table to download items to detailed analysis): 'GREEN GIANT GARDEN THERMOMETER', 'HEARTS WRAPPING TAPE ', 'LARGE CAKE TOWEL PINK SPOTS', BABUSHKA 65CMx65CM', 'POMPOM CURTAIN', 'POP ART PUSH DOWN RUBBER ', 'RETROSPOT S DOILEY', 'SET 36 COLOUR PENCILS DOLLY GIRL', 'SET 36 COLOUR PENCILS LOVE LONDON', 'SET 36 COLOURING PENCILS DOILEY',"
      ],
      "metadata": {
        "id": "2OKY0z84lh0M"
      },
      "id": "2OKY0z84lh0M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows and check for columns\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in the dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Clean the dataset: Remove rows with missing values in key columns\n",
        "columns_to_check = ['InvoiceNo', 'CustomerID', 'Quantity', 'UnitPrice']\n",
        "df.dropna(subset=columns_to_check, inplace=True)\n",
        "\n",
        "# 1. Calculate total sales revenue\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "total_revenue = df['TotalPrice'].sum()\n",
        "\n",
        "# 2. Identify top-selling product\n",
        "top_products = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False)\n",
        "top_product = top_products.idxmax()\n",
        "top_product_sales = top_products.max()\n",
        "top_product_percentage = (top_product_sales / total_revenue) * 100\n",
        "\n",
        "# 3. Calculate unique customers and average order value\n",
        "unique_customers = df['CustomerID'].nunique()\n",
        "average_order_value = df.groupby('InvoiceNo')['TotalPrice'].sum().mean()\n",
        "\n",
        "# 4. Revenue by country\n",
        "country_revenue = df.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False)\n",
        "top_countries = country_revenue.head(3)\n",
        "\n",
        "# 5. Calculate repeat purchases\n",
        "repeat_customers = df[df.duplicated(['CustomerID'], keep=False)]\n",
        "repeat_customer_count = repeat_customers['CustomerID'].nunique()\n",
        "repeat_purchase_percentage = (repeat_customer_count / unique_customers) * 100\n",
        "\n",
        "# 6. Identify stockout risk based on sales velocity\n",
        "product_sales = df.groupby('Description')['Quantity'].sum()\n",
        "low_stock_threshold = product_sales.mean()  # A simple threshold for example\n",
        "at_risk_products = product_sales[product_sales < low_stock_threshold].index.tolist()\n",
        "\n",
        "# Summary Insights\n",
        "summary_insights = {\n",
        "    'Total Sales Revenue': total_revenue,\n",
        "    'Top Selling Product': top_product,\n",
        "    'Top Product Percentage of Revenue': top_product_percentage,\n",
        "    'Unique Customers': unique_customers,\n",
        "    'Average Order Value': average_order_value,\n",
        "    'Top Countries Revenue': top_countries.to_dict(),  # Convert to dict for better display\n",
        "    'Repeat Purchase Percentage': repeat_purchase_percentage,\n",
        "    'At Risk Stockout Products': at_risk_products\n",
        "}\n",
        "\n",
        "# Output the summary insights\n",
        "print(\"\\nSummary Insights:\")\n",
        "for key, value in summary_insights.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "fOeTJG8-l2He"
      },
      "id": "fOeTJG8-l2He",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}